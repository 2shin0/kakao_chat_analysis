import streamlit as st
from preprocessing import katalk_msg_parse
from analysis import generate_basic_statistics, generate_wordcloud, perform_sentiment_analysis, making_topic_modeling, making_cluster
from utils import load_uploaded_file
import pandas as pd
from streamlit_option_menu import option_menu

st.set_page_config(
    page_title="ì¹´í†¡ ë°ì´í„° ë¶„ì„ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_data
def load_and_process_data(uploaded_file):
    df = katalk_msg_parse(uploaded_file)
    return df


with st.sidebar:
    choice = option_menu("", ["ë°ì´í„°","ë°ì´í„° ë¶„ì„"],
    icons=['house', 'bi bi-check2-all'],
    menu_icon="app-indicator", default_index=0,
    styles={
    "container": {"padding": "4!important", "background-color": "#fafafa"},
    "icon": {"color": "black", "font-size": "25px"},
    "nav-link": {"font-size": "16px", "text-align": "left", "margin":"0px", "--hover-color": "#fafafa"},
    "nav-link-selected": {"background-color": "#08c7b4"},
    }
    )

if choice == 'ë°ì´í„°':
    st.title('ì¹´í†¡ ë°ì´í„° ë¶„ì„ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜')
    st.write("ì•„ë˜ íŒŒì¼ ì—…ë¡œë“œ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì¹´í†¡ ë°ì´í„°(.txt íŒŒì¼)ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”!")

    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["txt"])

    if uploaded_file:
        df = load_and_process_data(uploaded_file)
        st.sidebar.subheader('ì „ì²˜ë¦¬')
        st.sidebar.write("í•„í„°ë§ ì—†ì´ ì ìš© ë²„íŠ¼ì„ ëˆ„ë¥´ì‹œë©´ ì „ì²´ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        min_date = df['date_time'].min().date()
        max_date = df['date_time'].max().date()

        st.sidebar.subheader('í•„í„°ë§')
        user = st.sidebar.text_input("ì‚¬ìš©ìëª…")
        text_filter = st.sidebar.text_input("ë‚´ìš© í•„í„°")
        start_date = st.sidebar.date_input("ì‹œì‘ ë‚ ì§œ", min_value=min_date, max_value=max_date, value=min_date)
        end_date = st.sidebar.date_input("ë ë‚ ì§œ", min_value=min_date, max_value=max_date, value=max_date)

        df['date_time'] = pd.to_datetime(df['date_time'], format='%Y. %m. %d. %p %I:%M')

        start_date = pd.to_datetime(start_date)
        end_date = pd.to_datetime(end_date)

        if st.sidebar.button('ì ìš©'):
            df_filtered = df[(df['date_time'] >= start_date) & (df['date_time'] <= end_date)]
            if user:
                df_filtered = df_filtered[df_filtered['user_name'].str.contains(user, case=False, na=False)]
            if text_filter:
                df_filtered = df_filtered[df_filtered['text'].str.contains(text_filter, case=False, na=False)]
            
            # Save to session state
            st.session_state.df_filtered = df_filtered
            
            st.info("ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì™¼ìª½ 'ë°ì´í„° ë¶„ì„' ë©”ë‰´ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
            st.write(df_filtered)



elif choice == 'ë°ì´í„° ë¶„ì„':
    st.title('ë°ì´í„° ë¶„ì„')
    
    if 'df_filtered' in st.session_state:
        df_filtered = st.session_state.df_filtered
        
        # Tabs for analysis
        tabs = st.tabs(['ê¸°ë³¸ í†µê³„', 'ì›Œë“œí´ë¼ìš°ë“œ', 'ê°ì • ë¶„ì„', 'í† í”½ ë¶„ì„', 'êµ°ì§‘ ë¶„ì„'])
        
        with tabs[0]:
            statistics_image = generate_basic_statistics(df_filtered)
            st.image(statistics_image)
        
        with tabs[1]:
            wordcloud_img = generate_wordcloud(df_filtered)
            st.image(wordcloud_img)
        
        with tabs[2]:
            sentiment_results = perform_sentiment_analysis(df_filtered)
            st.write(sentiment_results)
        
        with tabs[3]:
            true, false = making_topic_modeling(df_filtered)
            
            st.write('#### ê¸ì • ì±„íŒ… í† í”½ ë¶„ì„')
            st.write(true)
            
            st.write('#### ë¶€ì • ì±„íŒ… í† í”½ ë¶„ì„')
            st.write(false)
        with tabs[4]:
            clustering_img = making_cluster(df_filtered)
            st.image(clustering_img)
    else:
        st.write("ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")